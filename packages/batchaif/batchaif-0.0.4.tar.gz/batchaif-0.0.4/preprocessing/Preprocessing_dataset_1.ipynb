{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining workdir path\n",
    "workdir = '../'\n",
    "\n",
    "# Labels in adata for batch removal\n",
    "batch_key = 'batch'\n",
    "cell_type_key = 'cell_type'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset 1 - Human Dendritic Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "data = pd.read_table(f'{workdir}/data/dataset_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving cell types, batches, single cell types from columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datafranme containing Cell Type, Batch ID, Single Cell Type\n",
    "cell_types = np.array(list(data.columns.values))\n",
    "cell_types = np.array([x.split(\"_\") for x in cell_types])\n",
    "\n",
    "d = {'Cell Type': cell_types[:,0], 'Batch ID': cell_types[:,1],'Single cell ID' : cell_types[:,2]}\n",
    "d = pd.DataFrame(data=d).T\n",
    "d.columns = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing information and keeping desired cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating meta_data \n",
    "d_1 = d[d.columns.values[d.loc['Batch ID'].isin(['P7','P8','P9','P10'])]]\n",
    "d_2 = d[d.columns.values[d.loc['Batch ID'].isin(['P3','P4','P13','P14'])]]\n",
    "d1 = d_1[d_1.columns.values[d_1.loc['Cell Type'].isin(['CD141','pDC','DoubleNeg'])]]\n",
    "d2 = d_2[d_2.columns.values[d_2.loc['Cell Type'].isin(['pDC','DoubleNeg','CD1C'])]]\n",
    "d_ = pd.concat((d1,d2),axis=1)\n",
    "meta_data = pd.DataFrame.transpose(pd.concat((d1,d2),axis=1))\n",
    "Batch = ['B2' for i in range (meta_data.shape[0])]\n",
    "Batch[:d1.shape[1]]=['B1' for i in range (d1.shape[1])]\n",
    "meta_data[batch_key]=Batch\n",
    "meta_data[cell_type_key] = meta_data['Cell Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing identical cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into two batches\n",
    "Batch_1 = data[d.columns.values[d.loc['Batch ID'].isin(['P7','P8','P9','P10'])]]\n",
    "Batch_2 = data[d.columns.values[d.loc['Batch ID'].isin(['P3','P4','P13','P14'])]]\n",
    "\n",
    "# Separate into two batches with non-identical cell types\n",
    "Batch_1 = Batch_1[Batch_1.columns.values[d_1.loc['Cell Type'].isin(['CD141','pDC','DoubleNeg'])]]\n",
    "Batch_2 = Batch_2[Batch_2.columns.values[d_2.loc['Cell Type'].isin(['pDC','DoubleNeg','CD1C'])]]\n",
    "\n",
    "Batch_1_num = Batch_1.to_numpy()\n",
    "Batch_2_num = Batch_2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating preprocessed data\n",
    "Input_ = pd.concat((Batch_1,Batch_2),axis=1)\n",
    "Input_ = pd.concat((Input_,meta_data[[batch_key,cell_type_key]].T),axis=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_norm = sc.pp.normalize_per_cell(Input_.iloc[:,:-2],\n",
    "                                      counts_per_cell_after=1,copy=True)\n",
    "Input_norm = pd.concat([Input_norm, Input_.iloc[:,-2:]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log1p and normalization of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_norm_log = sc.pp.log1p(sc.pp.normalize_per_cell(Input_.iloc[:,:-2],copy=True).values)\n",
    "Input_norm_log = np.concatenate([Input_norm_log, Input_.iloc[:,-2:]],axis=1)\n",
    "Input_norm_log = pd.DataFrame(Input_norm_log, index=Input_norm.index, columns=Input_norm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_.to_csv(f'{workdir}/data_preprocessed/dataset_1.csv', index=True)\n",
    "Input_norm.to_csv(f'{workdir}/data_preprocessed/dataset_1_norm.csv',index=True)\n",
    "Input_norm_log.to_csv(f'{workdir}/data_preprocessed/dataset_1_norm_log.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the preprocessed file use the following command\n",
    "`pd.read_csv('./data_preprocessed/dataset_1.csv',index_col=0,header=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to AnnData format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating annotated matrix in AnnData format with expression matrix\n",
    "adata = anndata.AnnData(X = np.array(Input_.iloc[:,:-2]))\n",
    "\n",
    "# Adding cell type and batch as observations\n",
    "adata.obs[cell_type_key] = Input_[cell_type_key].tolist()\n",
    "adata.obs[batch_key] = Input_[batch_key].tolist()\n",
    "\n",
    "# Creating annotated matrix in AnnData format with expression matrix\n",
    "adata_norm = anndata.AnnData(X = np.array(Input_norm.iloc[:,:-2]))\n",
    "\n",
    "# Adding cell type and batch as observations\n",
    "adata_norm.obs[cell_type_key] = Input_norm[cell_type_key].tolist()\n",
    "adata_norm.obs[batch_key] = Input_norm[batch_key].tolist()\n",
    "\n",
    "# Creating annotated matrix in AnnData format with expression matrix\n",
    "adata_norm_log = anndata.AnnData(X = np.array(Input_norm_log.iloc[:,:-2]))\n",
    "\n",
    "# Adding cell type and batch as observations\n",
    "adata_norm_log.obs[cell_type_key] = Input_norm_log[cell_type_key].tolist()\n",
    "adata_norm_log.obs[batch_key] = Input_norm_log[batch_key].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lily/Documents/MICS/batch_effects_biomed/preprocessing/preproc_env/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/lily/Documents/MICS/batch_effects_biomed/preprocessing/preproc_env/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'batch' as categorical\n",
      "/Users/lily/Documents/MICS/batch_effects_biomed/preprocessing/preproc_env/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'cell_type' as categorical\n",
      "/Users/lily/Documents/MICS/batch_effects_biomed/preprocessing/preproc_env/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  c.reorder_categories(natsorted(c.categories), inplace=True)\n",
      "... storing 'batch' as categorical\n"
     ]
    }
   ],
   "source": [
    "adata.write(f'{workdir}/data_preprocessed/dataset_1.h5ad')\n",
    "adata_norm.write(f'{workdir}/data_preprocessed/dataset_1_norm.h5ad')\n",
    "adata_norm_log.write(f'{workdir}/data_preprocessed/dataset_1_norm_log.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the preprocessed file use the following command\n",
    "`sc.read('./data_preprocessed/dataset_1.h5ad')`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preproc",
   "language": "python",
   "name": "preproc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
