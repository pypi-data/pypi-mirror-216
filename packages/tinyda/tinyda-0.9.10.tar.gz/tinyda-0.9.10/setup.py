# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['tinyDA']

package_data = \
{'': ['*']}

install_requires = \
['arviz>=0.12.1,<0.13.0',
 'matplotlib>=3.5.2,<4.0.0',
 'numpy>=1.23.0,<2.0.0',
 'scipy>=1.8.0,<2.0.0',
 'tqdm>=4.64.0,<5.0.0']

setup_kwargs = {
    'name': 'tinyda',
    'version': '0.9.10',
    'description': 'Delayed Acceptance MCMC Sampler',
    'long_description': "![](https://github.com/mikkelbue/tinyDA/blob/main/misc/tinyDA.png)\n\n# tinyDA\nMultilevel Delayed Acceptance MCMC sampler with finite-length subchain sampling and adaptive error modelling. This is intended as a simple, lightweight implementation, with minimal dependencies, i.e. nothing beyond the SciPy stack and ArviZ. It is fully imperative and easy to use!\n\nFor instructions, have a look at the [documentation](https://tinyda.readthedocs.io/en/latest/), the [examples](https://github.com/mikkelbue/tinyDA/tree/main/examples) or the [usage section below](#usage).\n\n## Installation\ntinyDA can be installed from PyPI:\n```\npip install tinyDA\n```\n\n## Dependencies\n* NumPy\n* SciPy\n* ArviZ\n* tqdm\n* [Ray](https://docs.ray.io/en/master/) (multiprocessing, optional)\n\n## Features\n\n### Samplers\n* Metropolis-Hastings\n* Delayed Acceptance (Christen & Fox, 2005)\n* Multilevel Delayed Acceptance (Lykkegaard et al. 2022)\n\n### Proposals\n* Random Walk Metropolis Hastings (RWMH) - Metropolis et al. (1953), Hastings (1970)\n* preconditioned Crank-Nicolson (pCN) - Cotter et al. (2013)\n* Adaptive Metropolis (AM) - Haario et al. (2001)\n* Operator-weighted pCN - Law (2014)\n* DREAM(Z) - Vrugt (2016)\n* Multiple-Try Metropolis (MTM) - Liu et al. (2000)\n\n### Adaptive Error Models\n* State independent - Cui et al. (2018)\n* State dependent - Cui et al. (2018)\n\n### Diagnostics\n* Convert a tinyDA chain to an ArviZ InferenceData object for near-unlimited diagnostics!\n\n## Usage\nDocumentation is available at [Read the Docs](https://tinyda.readthedocs.io/en/latest/). A few illustrative examples are available as Jupyter Notebooks in the root directory. Below is a short summary of the core features.\n\n### Distributions\nThe prior and likelihood can be defined using standard `scipy.stats` classes:\n```python\nimport tinyDA as tda\n\nfrom scipy.stats import multivariate_normal\n\n# set the prior mean and covariance.\nmean_prior = np.zeros(n_dim)\ncov_prior = np.eye(n_dim)\n\n# set the covariance of the likelihood.\ncov_likelihood = sigma**2*np.eye(data.shape[0])\n\n# initialise the prior distribution and likelihood.\nmy_prior = multivariate_normal(mean_prior, cov_prior)\nmy_loglike = tda.GaussianLogLike(data, cov_likelihood)\n```\nIf using a Gaussian likelihood, we recommend using the `tinyDA` implementation, since it is unnormalised and plays along well with `tda.AdaptiveLogLike` used for the Adaptive Error Model. Home-brew distributions can easily be defined, and must have a `.rvs()` method for drawing random samples and a `logpdf(x)` method for computing the log-likelihood, as per the `SciPy` implementation.\n\n### tinyDA.Posterior\nThe heart of the TinyDA sampler is the `tinyDA.Posterior`, which is responsible for:\n1. Calling the model with some parameters (a proposal) and collecting the model output.\n2. Evaluating the prior density of the parameters, and the likelihood of the data, given the parameters.\n3. Constructing `tda.Link` instances that hold information for each sample.\n\n![](https://github.com/mikkelbue/tinyDA/blob/main/misc/flowchart.png)\n\nThe `tinyDA.Posterior` takes as input the prior, the likelihood, and a forward model. Therefore, a forward model must be defined. This model can be either a function `model_output = my_function(parameters)` or a class instance with a `.__call__(self, parameters)` method. The function or `__call__` method must return either just the model output or a tuple of `(model_output, qoi)`. In this example, we define a class that performs simple linear regression on whatever inputs `x` we have.\n\n```python\nclass MyLinearModel:\n    def __init__(self, x):\n\n        self.x = x\n        \n    def __call__(self, parameters):\n        \n        # the model output is a simple linear regression\n        model_output = parameters[0] + parameters[1]*self.x\n        \n        # no quantity of interest beyond the parameters.\n        qoi = None\n        \n        # return both.\n        return model_output, qoi\n\nmy_model = MyLinearModel(x)\nmy_posterior = tda.Posterior(my_prior, my_loglike, my_model)\n```\n\n### Proposals\nA proposal is simply initialised with its parameters:\n```python\n# set the covariance of the proposal distribution.\nam_cov = np.eye(n_dim)\n\n# set the number of iterations before starting adaptation.\nam_t0 = 1000\n\n# set some adaptive metropolis tuning parameters.\nam_sd = 1\nam_epsilon = 1e-6\n\n# initialise the proposal.\nmy_proposal = tda.AdaptiveMetropolis(C0=am_cov, t0=am_t0, sd=am_sd, epsilon=am_epsilon)\n```\n\n### Sampling\nAfter defining a proposal, a coarse posterior `my_posterior_coarse`, and a fine posterior `my_posterior_fine`, the Delayed Acceptance sampler can be run using `tinyDA.sample()`:\n```python\nmy_chains = tda.sample([my_posterior_coarse, my_posterior_fine], \n                       my_proposal, \n                       iterations=12000, \n                       n_chains=2, \n                       subsampling_rate=10)\n```\n\nIf using a hirarchy with more than two models, a Multilevel Delayed Acceptance sampler can be run by supplying a list of posteriors in ascending order and a correponsing list of subsampling rates:\n```python\nmy_chains = tda.sample([my_posterior_level0, \n                        my_posterior_level1, \n                        my_posterior_level2, \n                        my_posterior_level3], \n                       my_proposal, \n                       iterations=12000, \n                       n_chains=2, \n                       subsampling_rate=[10, 5, 5])\n```\n\n### Postprocessing\nThe entire sampling history is now stored in `my_chains` in the form of a dictionary with tinyDA.Link instances. You can convert the output of `tinyDA.sample()` to an ArviZ InferenceData object with \n```python\nidata = tda.to_inference_data(my_chains, burnin=2000)\n```\nIf you want to have a look at the coarse samples, you can pass an additional argument:\n```python\nidata = tda.to_inference_data(my_chains, level='coarse', burnin=20000)\n```\n\nThe `idata` object can then be used with the ArviZ diagnostics suite to e.g. get MCMC statistics, plot the traces and so on.\n\n## Contributing\nI (mikkelbue) am currently the sole contributor to this package. I have been using it in my own research, and have so far been developing it (mostly) for myself. \n\nIf you feel that it is missing some features, or that something could be improved, please do not hesitate to create a fork and submit a PR! If you want to help me improve the package, please have a look at the [issues](https://github.com/mikkelbue/tinyDA/issues) and consider if something seems doable to you. I am currently working on a scientific paper that I plan to submit to Journal of Statistical Software, and would be happy for other people to get involved.\n\nIf you would like to contribute, please consider the following:\n* I am hoping to keep the list of dependencies **short**, and would rather not include any additional large libraries, unless it is strongly warranted. Great things can be achieved using NumPy!\n* I am pretty good at converting theoretical methods into computer code, but I am not a software engineer. Any kind of CI, tests and improvements to the software infrastructure would be greatly appreciated!\n\n## TODO\n* ~~Parallel multi-chain sampling~~\n* ~~More user-friendly diagnostics~~\n* ~~Multilevel Delayed Acceptance~~\n* Variance Reduction\n* MALA proposal\n* Wrapper for framework-agnostic adaptive coarse model\n* Embedded spaces for hierachical models\n* Tests\n\n\n",
    'author': 'Mikkel Bue Lykkegaard',
    'author_email': 'mikkelbue@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/mikkelbue/tinyda',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.8,<3.12',
}


setup(**setup_kwargs)
