Metadata-Version: 2.1
Name: databricks-session
Version: 0.1.8
Summary: A simple util to get a spark and mlflow session objects from an .env file
Home-page: https://github.com/Broomva/databricks_session
Author: Carlos D. Escobar-Valbuena
Author-email: carlosdavidescobar@gmail.com
License: MIT
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: alembic (==1.11.1)
Requires-Dist: arrow (==1.2.3)
Requires-Dist: black (==23.3.0)
Requires-Dist: blinker (==1.6.2)
Requires-Dist: certifi (==2023.5.7)
Requires-Dist: charset-normalizer (==3.1.0)
Requires-Dist: click (==8.1.3)
Requires-Dist: cloudpickle (==2.2.1)
Requires-Dist: contourpy (==1.1.0)
Requires-Dist: cycler (==0.11.0)
Requires-Dist: databricks-cli (==0.17.7)
Requires-Dist: databricks-connect (==13.1.0)
Requires-Dist: databricks-sdk (==0.1.11)
Requires-Dist: docker (==6.1.3)
Requires-Dist: entrypoints (==0.4)
Requires-Dist: Flask (==2.3.2)
Requires-Dist: fonttools (==4.40.0)
Requires-Dist: gitdb (==4.0.10)
Requires-Dist: GitPython (==3.1.31)
Requires-Dist: googleapis-common-protos (==1.59.1)
Requires-Dist: greenlet (==2.0.2)
Requires-Dist: grpcio (==1.56.0)
Requires-Dist: grpcio-status (==1.56.0)
Requires-Dist: gunicorn (==20.1.0)
Requires-Dist: idna (==3.4)
Requires-Dist: importlib-metadata (==6.7.0)
Requires-Dist: iniconfig (==2.0.0)
Requires-Dist: itsdangerous (==2.1.2)
Requires-Dist: Jinja2 (==3.1.2)
Requires-Dist: jinja2-time (==0.2.0)
Requires-Dist: joblib (==1.2.0)
Requires-Dist: kiwisolver (==1.4.4)
Requires-Dist: make (==0.1.6.post2)
Requires-Dist: Mako (==1.2.4)
Requires-Dist: Markdown (==3.4.3)
Requires-Dist: MarkupSafe (==2.1.3)
Requires-Dist: matplotlib (==3.7.1)
Requires-Dist: mlflow (==2.4.1)
Requires-Dist: mypy-extensions (==1.0.0)
Requires-Dist: numpy (==1.25.0)
Requires-Dist: oauthlib (==3.2.2)
Requires-Dist: packaging (==23.1)
Requires-Dist: pandas (==2.0.2)
Requires-Dist: pathspec (==0.11.1)
Requires-Dist: Pillow (==9.5.0)
Requires-Dist: platformdirs (==3.8.0)
Requires-Dist: pluggy (==1.2.0)
Requires-Dist: protobuf (==4.23.3)
Requires-Dist: py4j (==0.10.9.7)
Requires-Dist: pyarrow (==12.0.1)
Requires-Dist: pydantic (==1.10.9)
Requires-Dist: PyJWT (==2.7.0)
Requires-Dist: pyparsing (==3.1.0)
Requires-Dist: pytest (==7.4.0)
Requires-Dist: python-dateutil (==2.8.2)
Requires-Dist: python-dotenv (==1.0.0)
Requires-Dist: pytz (==2023.3)
Requires-Dist: PyYAML (==6.0)
Requires-Dist: querystring-parser (==1.2.4)
Requires-Dist: requests (==2.31.0)
Requires-Dist: scikit-learn (==1.2.2)
Requires-Dist: scipy (==1.11.0)
Requires-Dist: six (==1.16.0)
Requires-Dist: smmap (==5.0.0)
Requires-Dist: SQLAlchemy (==2.0.17)
Requires-Dist: sqlparse (==0.4.4)
Requires-Dist: tabulate (==0.9.0)
Requires-Dist: threadpoolctl (==3.1.0)
Requires-Dist: typing-extensions (==4.6.3)
Requires-Dist: tzdata (==2023.3)
Requires-Dist: urllib3 (==1.26.16)
Requires-Dist: websocket-client (==1.6.1)
Requires-Dist: Werkzeug (==2.3.6)
Requires-Dist: zipp (==3.15.0)
Provides-Extra: protobuf
Requires-Dist: protobuf (<5.0.0dev) ; extra == 'protobuf'

# Databricks Session Util
**A simple utility for spark and mlflow session objects**


## Setup

### Quick Install

```shell
python -m pip install databricks_session
```

### Build from source

Clone the repository

```shell
git clone https://github.com/Broomva/databricks_session.git
```

Install the package

``` shell
cd databricks_session && make install
```

### Build manually

After cloning, create a virtual environment

```shell
conda create -n databricks_session python=3.10
conda activate databricks_session
```

Install the requirements

```shell
pip install -r requirements.txt
```

Run the python installation

```shell
python setup.py install
```

## Usage

The deployment requires a .env file created under local folder:

```shell
touch .env
```

It should have a schema like this:

```toml
databricks_experiment_name=''
databricks_experiment_id=''
databricks_host=''
databricks_token=''
databricks_username=''
databricks_password=''
databricks_cluster_id=''
```

```python
import databricks_session 

# Create a Snowpark session
spark = DatabricksSparkSession().get_session()

# Connect to MLFLow Artifact Server
mlflow_session = DatabricksMLFlowSession().get_session()
```
