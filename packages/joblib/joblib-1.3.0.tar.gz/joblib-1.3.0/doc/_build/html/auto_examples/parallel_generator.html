
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Returning a generator in joblib.Parallel &#8212; joblib 1.3.0.dev0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Improving I/O using compressors" href="compressors_comparison.html" />
    <link rel="prev" title="NumPy memmap in joblib.Parallel" href="parallel_memmap.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-parallel-generator-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="returning-a-generator-in-joblib-parallel">
<span id="sphx-glr-auto-examples-parallel-generator-py"></span><h1>Returning a generator in joblib.Parallel<a class="headerlink" href="#returning-a-generator-in-joblib-parallel" title="Permalink to this heading">¶</a></h1>
<p>This example illustrates memory optimization enabled by using
<a class="reference internal" href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> to get a generator on the outputs of parallel jobs.
We first create tasks that return results with large memory footprints.
If we call <a class="reference internal" href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a> for several of these tasks directly, we
observe a high memory usage, as all the results are held in RAM before being
processed</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">return_generator=True</span></code> option allows to progressively consumes
the outputs as they arrive and keeps the memory at an acceptable level.</p>
<section id="memorymonitor-helper">
<h2><code class="docutils literal notranslate"><span class="pre">MemoryMonitor</span></code> helper<a class="headerlink" href="#memorymonitor-helper" title="Permalink to this heading">¶</a></h2>
<p>The following class is an helper to monitor the memory of the process and its
children in another thread, so we can display it afterward.</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">psutil</span></code> to monitor the memory usage in the code. Make sure it
is installed with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">psutil</span></code> for this example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">psutil</span> <span class="kn">import</span> <span class="n">Process</span>
<span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class"><span class="n">Thread</span></a>


<span class="k">class</span> <span class="nc">MemoryMonitor</span><span class="p">(</span><a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class"><span class="n">Thread</span></a><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Monitor the memory usage in MB in a separate thread.</span>

<span class="sd">    Note that this class is good enough to highlight the memory profile of</span>
<span class="sd">    Parallel in this example, but is not a general purpose profiler fit for</span>
<span class="sd">    all cases.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Get memory of a process and its children.&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Process</span><span class="p">()</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">memory</span> <span class="o">+=</span> <span class="n">c</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span>
        <span class="k">return</span> <span class="n">memory</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">memory_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_memory</span><span class="p">()</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_memory</span><span class="p">()</span> <span class="o">-</span> <span class="n">memory_start</span><span class="p">)</span>
            <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">join</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="save-memory-by-consuming-the-outputs-of-the-tasks-as-fast-as-possible">
<h2>Save memory by consuming the outputs of the tasks as fast as possible<a class="headerlink" href="#save-memory-by-consuming-the-outputs-of-the-tasks-as-fast-as-possible" title="Permalink to this heading">¶</a></h2>
<p>We create a task whose output takes about 15MB of RAM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">return_big_object</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mf">.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">i</span> <span class="o">*</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ones</span></a><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float64</span></a><span class="p">)</span>
</pre></div>
</div>
<p>We create a reduce step. The input will be a generator on big objects
generated in parallel by several instances of <code class="docutils literal notranslate"><span class="pre">return_big_object</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accumulator_sum</span><span class="p">(</span><span class="n">generator</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">value</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
<p>We process many of the tasks in parallel. If <cite>return_generator=False</cite>
(default), we should expect a usage of more than 2GB in RAM. Indeed, all the
results are computed and stored in <code class="docutils literal notranslate"><span class="pre">res</span></code> before being processed by
<cite>accumulator_sum</cite> and collected by the gc.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class"><span class="n">Parallel</span></a><span class="p">,</span> <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a>

<span class="n">monitor</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class"><span class="n">MemoryMonitor</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running tasks with return_generator=False...&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_generator</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<a href="https://docs.python.org/3/library/threading.html#threading.Thread.join" title="threading.Thread.join" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-method"><span class="n">monitor</span><span class="o">.</span><span class="n">join</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">peak</span></a> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">monitor</span><span class="o">.</span><span class="n">memory_buffer</span></a><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">peak</span></a><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running tasks with return_generator=False...
Accumulate results:......................................................................................................................................................
All tasks completed and reduced successfully.
Peak memory usage: 2.61GB
</pre></div>
</div>
<p>If we use <code class="docutils literal notranslate"><span class="pre">return_generator=True</span></code>, <code class="docutils literal notranslate"><span class="pre">res</span></code> is simply a generator with the
results that are ready. Here we consume the results as soon as they arrive
with the <code class="docutils literal notranslate"><span class="pre">accumulator_sum</span></code> and once they have been used, they are collected
by the gc. The memory footprint is thus reduced, typically around 300MB.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">monitor_gen</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class"><span class="n">MemoryMonitor</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Create result generator with return_generator=True...&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_generator</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<a href="https://docs.python.org/3/library/threading.html#threading.Thread.join" title="threading.Thread.join" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-method"><span class="n">monitor_gen</span><span class="o">.</span><span class="n">join</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">peak</span></a> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">monitor_gen</span><span class="o">.</span><span class="n">memory_buffer</span></a><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">peak</span></a><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Create result generator with return_generator=True...
Accumulate results:......................................................................................................................................................
All tasks completed and reduced successfully.
Peak memory usage: 227.38MB
</pre></div>
</div>
<p>We can then report the memory usage accross time of the two runs using the
MemoryMonitor.</p>
<p>In the first case, as the results accumulate in <code class="docutils literal notranslate"><span class="pre">res</span></code>, the memory grows
linearly and it is freed once the <code class="docutils literal notranslate"><span class="pre">accumulator_sum</span></code> function finishes.</p>
<p>In the second case, the results are processed by the accumulator as soon as
they arrive, and the memory does not need to be able to contain all
the results.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">monitor</span><span class="o">.</span><span class="n">memory_buffer</span></a><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_generator=False&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">monitor_gen</span><span class="o">.</span><span class="n">memory_buffer</span></a><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_generator=True&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([],</span> <span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Memory usage&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">1e7</span><span class="p">,</span> <span class="mf">1e8</span><span class="p">,</span> <span class="mf">1e9</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;10MB&#39;</span><span class="p">,</span> <span class="s1">&#39;100MB&#39;</span><span class="p">,</span> <span class="s1">&#39;1GB&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_parallel_generator_001.png" srcset="../_images/sphx_glr_parallel_generator_001.png" alt="parallel generator" class = "sphx-glr-single-img"/><p>It is important to note that with <code class="docutils literal notranslate"><span class="pre">return_generator</span></code>, the results are
still accumulated in RAM after computation. But as we asynchronously process
them, they can be freed sooner. However, if the generator is not consumed
the memory still grows linearly.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  21.363 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-parallel-generator-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3fa10e137733c0c23e90dca9a693a9e7/parallel_generator.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">parallel_generator.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/db658a25107c199addf4f0b83d7dc5ac/parallel_generator.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">parallel_generator.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/joblib_logo.svg" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../why.html">Why joblib: project goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Installing joblib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory.html">On demand recomputing: the <cite>Memory</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel.html">Embarrassingly parallel for loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../persistence.html">Persistence</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#id1">General examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#parallel-examples">Parallel examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developing.html">Development</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.Memory.html">joblib.Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.Parallel.html">joblib.Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.parallel_config.html">joblib.parallel_config</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.dump.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.load</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.hash.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.hash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.register_compressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.register_compressor</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2008-2021, Joblib developers.
      
      |
      <a href="../_sources/auto_examples/parallel_generator.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>